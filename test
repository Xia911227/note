







测试用例规范




版本记录
版本	作者	发布日期	更新内容
V1.0	冯华玉	2022.08.24	新建
			
			
			
			
			
			
			
 
目录
1	概述	3
1.1	目的	3
1.2	适用范围	3
2	测试用例介绍	3
2.1	什么是测试用例	3
2.2	测试用例的重要性	3
2.3	测试用例的编写目的和作用	4
2.4	测试用例的编写依据	4
2.5	测试用例分类	5
3	测试用例设计方法	6
3.1	白盒测试用例设计方法	6
3.1.1	逻辑覆盖	6
3.1.2	路径设计法	7
3.2	黑盒测试用例设计方法	8
3.2.1	边界值法	8
3.2.2	等价类法	8
3.2.3	场景法	9
3.2.4	正交试验法	10
3.2.5	判定表法	10
3.2.6	错误推测法	11
3.3	兼容性测试用例设计	11
3.4	易用性测试用例设计	12
3.5	迁移测试用例设计	13
3.6	性能测试用例设计	14
3.7	安全测试用例设计	14
4	测试用例设计原则	17
4.1	测试用例设计核心思想	17
4.2	测试用例设计技巧	18
4.2.1	通用功能测试用例设计	18
4.2.2	涉及数字的测试用例设计	19
4.2.3	涉及日期的测试用例设计	19
4.2.4	涉及输入框的测试用例设计	19
4.2.5	涉及按钮的测试用例设计	20
4.2.6	涉及下拉、单选、复选框的测试用例设计	20
4.2.7	涉及分页的测试用例设计	20
4.2.8	涉及弹窗的测试用例设计	20
4.2.9	测试用例设计的共性	20
4.3	测试用例设计步骤	23
5	测试用例编写及管理	25
5.1	测试用例编写规范	25
5.1.1	测试用例命名规则	25
5.1.2	测试用例编号规则	25
5.1.3	测试用例文档书写内容	25
5.1.4	测试用例编写注意事项	26
5.2	测试用例管理	26
5.2.1	目录	26
5.2.2	优先级	26
5.2.3	用例评审	27
5.2.4	用例维护	30
6	测试用例执行	31
6.1	测试用例执行结果	31
6.2	相关度量	31
7	相关模板	33





















1	概述
1.1	目的
1.	统一测试用例规范，为测试设计人员提供测试用例设计、编写、管理及执行的指导
2.	为用例的质量负责，使用例编写工作能够有序、合理；
3.	能有效的提高系统所有功能点的覆盖率。
4.	提高编写的测试用例的可读性，可执行性、合理性。为测试执行人员更好执行测试，提高测试效率，最终提高整个产品的质量。
1.2	适用范围
主要适用于战略IT测试人员对软件产品的业务流程、功能测试用例的设计、编写、管理及执行等。
2	测试用例介绍
2.1	什么是测试用例
测试用例是为某个特殊目标而编制的一组测试输入，执行条件，以及预期结果，以便测试某个程序路径或核实是否满足某个特定需求。
测试用例包含测试目标，测试内容，测试环境，测试数据，测试步骤，预期结果等，并根据内容形成一份完整的文档。
2.2	测试用例的重要性
1.测试用例是软件测试的核心
2.测试用例是设计和制定测试过程的基础
3.测试用例是正常、有序、高效开展测试的核心基准
4.测试用例是将测试具体量化的方法之一
5.测试的覆盖度和深度与测试用例的数量成正比
6.测试用例是最终交付质量的核心保证之一
7.测试用例是对程序代码实现的质检手段之一

2.3	测试用例的编写目的和作用
对于测试人员：
1.指导测试的实施
2.对软件测试行为加以量化，避免盲目测试提高测试效率
3.规划测试数据的准备
对于测试管理者：
1.评估测试结果及交付质量的度量基准
2.评估测试规范性的依据之一
3.测试人员绩效考核的依据之一
4.分析缺陷的标准

2.4	测试用例的编写依据
在整个产品的研发过程中（瀑布模型），测试类型按照先后顺序主要分为：单元测试、集成测试、系统测试及产品确认，整个过程如下面的W模型所示：
 
图2.4.1研发过程W模型
测试用例的编写依据首先是需求文档，所有的测试用例都要根据用户的需求文档进行编写，但是根据软件生命周期每个阶段的不同，因此也会依据所在阶段的相关产出进行测试用例的设计。
 
图2.4.1测试用例设计参考依据
2.5	测试用例分类
按照测试用例的性质分为：
 	功能测试用例：包含单元功能测试用例，模块集成功能测试用例，系统功能测试用例等
 	接口测试用例：包括内部接口测试用例，外部接口测试用例等
 	业务测试用例：包括业务测试用例以及场景测试用例等
 	性能测试用例：包括性能测试用例，大容量测试用例，负载测试用例，压力测试用例等
 	安全测试用例：包括安全漏洞测试用例，sql注入测试用例，网络渗透测试用例，反信息泄露测试用例，爆源测试用例等。
按照测试阶段分为：
 	单元测试用例
 	集成测试用例
 	系统测试用例
 	UAT测试用例
3	测试用例设计方法
3.1	白盒测试用例设计方法
 
图3.1.1白盒测试用例设计方法
3.1.1	逻辑覆盖
逻辑覆盖根据覆盖目标的不同分为语句覆盖、判定覆盖、条件覆盖、判定/条件覆盖、组合覆盖和路径覆盖。
语句覆盖：选择足够多的测试用例，使得程序中的每个可执行语句至少执行一次。
判定覆盖：通过执行足够的测试用例，使得程序中的每个判定至少都获得一次“真”值和“假”值，即使程序中的每个取“真”分支和取“假”分支至少均经历一次，也称为“分支覆盖”。
条件覆盖：设计足够多的测试用例，使得程序中每个判定包含的每个条件的可能取值（真/假）都至少满足一次。
判定-条件覆盖：设计足够多的测试用例，使得程序中每个判定包含的每个条件的所有情况（真/假）至少出现一次，且每个判定本身的判定结果（真/假）也至少出现一次。顾名思义，判定-条件覆盖的测试用例一定同时满足判定覆盖和条件覆盖。
组合覆盖：通过执行足够的测试用例，使得程序中每个判定的所有可能的条件取值组合都至少出现一次。即满足组合覆盖的测试用例一定满足判定覆盖、条件覆盖和判定-条件覆盖。
路径覆盖：设计足够多的测试用例，要求覆盖程序中所有可能的路径。
 
图3.1.2六种逻辑覆盖之间的关系

3.1.2	路径设计法
基本路径:本质上是从程序入口到出口的一些通路。之所以称其为基本路径，原因在于可以通过对基本路径进行连接或者重复操作得到程序中的其它路径。
DD路径：又称决策到决策路径，指语句的一种序列，按照Miller的话说，从决策语句的“出路”开始，到下一个决策语句的“入路”结束，在这种序列中没有内部分支，因此对应的节点像排列起来的一行多米诺骨牌，当第一张牌推倒后，序列中的其他牌也会倒下
3.2	黑盒测试用例设计方法
 
图3.2.1黑盒测试用例设计方法
3.2.1	边界值法
定义：
边界值分析法就是对输入或输出的边界值进行测试的一种黑盒测试方法。通常边界值分析法是作为对等价类划分法的补充，这种情况下其测试用例来自等价类的边界。

设计方法：
	通常情况下，软件测试所包含的边界检验有几种类型：数字、字符、位置、质量、大小、速度、方位、尺寸、空间等
	相应地，以上类型的边界值应该在：最大/最小、首位/末位、上/下、最快/最慢、最高/最低、最短/最长、空/满等
	如果输入条件规定了值的范围，则应取刚达到这个范围的边界值，以及刚超越这个边界范围的值作为测试输入数据；
	如果输入条件规定了字符个数，则用最大字符数、最小字符数、比最大字符数多1、比最小字符数小1的数作为测试输入数据；

3.2.2	等价类法
定义：
等价类划分法是将程序所有可能的输入数据（有效的和无效的）划分成若干个等价类。然后从每个部分中选取具有代表性的数据当做测试用例进行合理的分类，测试用例由有效等价类和无效等价类的代表组成，从而保证测试用例具有完整性和代表性。等价类划分不仅可以用来确定测试用例中的数据的输入输出的精确取值范围，也可以用来准备中间值、状态和与时间相关的数据以及接口参数等，所以等价类可以用在系统测试、集成测试和组件测试中，在有明确的条件和限制的情况下，利用等价类划分技术可以设计出完备的测试用例。
设计方法：
	在输入条件规定的取值范围或值的个数的情况下，可以确定一个有效等价类和两个无效等价类。
	在规定了输入数据的一组值中（假定有n个值），并且程序要对每个输入值分别处理的情况下，可以确定n个有效等价类和一个无效等价类。
	在规定输入数据必须遵守的规则的情况下，可以确定一个有效等价类和若干个无效等价类。
	在输入条件规定了输入值的集合或规定了“必须如何”的条件下，可以确定一个有效等价类和一个无效等价类。
在确定已划分的等价类中各元素在程序处理中的方式不同的情况下，则应将该等价类进一步地划分为更小的等价类。

3.2.3	场景法
定义：
现在的软件几乎都是用事件触发来控制流程的，事件触发时的情景便形成了场景，而同一事件不同的触发顺序和处理结果就形成事件流。用例场景要通过描述流经用例的路径来确定，这个流经过程要从用例开始到结束遍历其中所有基本流和备选流。由此会产生很多组场景，如下图所示：
 
图3.2.2场景法
	基本流：经过测试用例最简单的路径。
	备选流：一个备选流可能从基本流开始，在某个特定条件下执行，然后重新加入基本流中（如备选流1和3）；也可能起源于另一个备选流（如备选流2），或者终止用例而不再重新加入到某个流（如备选流2和4）。
场景设计：
上图中经过用例的每条不同路径都反映了基本流和备选流，都用箭头来表示。基本流用直黑线来表示，是经过用例的最简单的路径。每个备选流自基本流开始之后，备选流会在某个特定条件下执行。备选流可能会重新加入基本流中（备选流 1 和 3），还可能起源于另一个备选流（备选流 2），或者终止用例而不再重新加入某个流（备选流 2 和 4）。从基本流开始，再将基本流和备选流结合起来，可以确定以下用例场景：
场景 1	基本流			
场景 2	基本流	备选流 1		
场景 3	基本流	备选流 1	备选流 2	
场景 4	基本流	备选流 3		
场景 5	基本流	备选流 3	备选流 1	
场景 6	基本流	备选流 3	备选流 1	备选流 2
场景 7	基本流	备选流 4		
场景 8	基本流	备选流 3	备选流 4	
3.2.4	正交试验法
定义：
正交试验法是研究多因子、多水平组合的一种试验法，它是利用正交表来对试验进行设计，通过少数的试验替代全面试验，根据正交表的正交性从全面试验中挑选适量的、有代表性的点进行试验，这些有代表性的点具备了“均匀分散，整齐可比”的特点。“均匀分散”性使试验点均衡地分布在试验范围内，让每个试验点有充分的代表性；“整齐可比”性使试验结果的分析十分方便，可以估计各因子对指标的影响，找出影响事物变化的主要因子。实践证明，正交试验法是一种解决多因子问题卓有成效的方法。
设计方法：
	对软件需求规格说明中的功能要求进行划分(层层分解与展开)，分解成具体的、相对独立的基本功能。
	根据基本功能的质量需求，找出影响其功能实现的操作对象和外部因素，每个因素的取值可以看作水平，多个取值就存在多个水平。
	确定待测试软件中所有因素及其权值，这是测试用例设计的关键，确保全面、准确。权值是依据各因素的影响范围、发生的频率和质量的需求来确定的。
	加权筛选，生成因素分析表。
	利用正交表构造测试数据集，正交表的每一行，就是一条测试用例。考虑交互作用不可忽略的处理因素和不可混杂的原则，有交互作用的组合优先安排。
3.2.5	判定表法
定义：
判定表是分析和表达多逻辑条件下执行不同操作的情况的工具，能够将复杂的问题按照各种可能的情况全部列举出来，简明并避免遗漏。
设计方法：
	判定表有几个要素： 
1)条件桩（Condition Stub）：列出了问题得所有条件。通常认为列出的条件的次序无关紧要。
2)动作桩（Action Stub）：列出了问题规定可能采取的操作。这些操作的排列顺序没有约束。
3)条件项（Condition Entry）：列出针对它左列条件的取值。在所有可能情况下的真假值。
4)动作项（Action Entry）：列出在条件项的各种取值情况下应该采取的动作。
	规则及规则合并：
1)规则：任何一个条件组合的特定取值及其相应要执行的操作称为规则。在判定表中贯穿条件项和动作项的一列就是一条规则。显然,判定表中列出多少组条件取值,也就有多少条规则,既条件项和动作项有多少列。
2)化简：就是规则合并有两条或多条规则具有相同的动作，并且其条件项之间存在着极为相似的关系。


3.2.6	错误推测法
推测法主要依赖经验、直觉来作出简单的判断甚至是猜测，给出可能存在缺陷的条件、场景等，在找到缺陷后，设计出相应的测试用例。错误推测法的基础是非常丰富的测试经验，用来做用例设计的补充，通常初级测试者不推荐使用该方法。
3.3	兼容性测试用例设计
平台兼容：兼容性测试用例设计时需要考虑测试对象的特性，对测试对象进行分析后结合硬件、软件考虑兼容性测试设计，如操作系统兼容，浏览器兼容，不同手机型号兼容等
版本兼容：兼容性测试用例设计时特别注意同类软件的区别和同一软件的不同版本情况，以进一步选取有针对性的兼容软件进行测试，如Android不同系统版本兼容，ios不同系统版本兼容，浏览器不同版本兼容，操作系统不同版本兼容等
分辨率兼容：分辨率兼容测试是为了验证页面版式、界面显示以及相关字符在不同的分辨率模式下显示的情况，如web端计算机的分辨率，手机端不同屏幕大小的分辨率等
数据兼容：兼容性测试用例设计时需要重点考虑数据兼容的问题，如数据类型的修改，数据的初始化等
注意：
①兼容性测试用例可通过整理一个软硬件兼容矩阵表，以使用频率进行优先排列，优先级高需要设计用例以完全覆盖。
②兼容性测试设计用例时同一类型的内容挑选代表性的用例即可。
Web端平台及浏览器兼容	系统	系统版本	浏览器	浏览器版本	测试结果	备注
	Windows	Win10	Chrome	104.0.5112.101	　	　
				95.0.5060.134 	　	　
			FireFox	100.0.2	　	　
				86.0.2	　	　
			IE 	11	　	　
				8	　	　
		win7	Chrome	104.0.5112.101	　	　
				95.0.5060.134 	　	　
			FireFox	100.0.2	　	　
				86.0.2	　	　
			IE 	IE11	　	　
				IE8	　	　
	macOS	OS10	safari	safari10	　	　
				safari9	　	　
			Chrome	104.0.5112.101	　	　
				95.0.5060.134 	　	　
			FireFox	100.0.2	　	　
				86.0.2	　	　
表3.3.1测试矩阵举例
3.4	易用性测试用例设计
易用性测试用例是系统交互适应性、系统功能实现以及系统功能有效性的一个集合体现，因此一定注意同功能测试用例的区分，以降低测试用例重复率。如页面元素展示是否完整正确属于功能范畴，元素展示位置大小是否合理，是否易于用户常用习惯操作属于易用性。易用性测试分为安装，功能，界面和辅助，所以测试用例也是从这四个方面进行设计。
	安装易用性：
1.	对安装手册和安装平台的评估。
2.	对安装的自动化程度测试，比如安装尽量全部自动化，手工的要尽量采用选择框等措施。
3.	安装选项和设置的测试。
4.	安装过程的中断测试，如断电、文件冲突等。
5.	对多环境安装测试，如标准、最低、笔记本等环境中测试。
6.	对安装的正确性测试，如考察对其他应用程序是否有影响。
7.	修复安装测试与卸载测试，如检查修复安装后是否有不良影响，是否能完全卸载，不能完全卸载时有无明确提示等。
	功能易用性：
主要测试业务符合性、功能定制性、业务模块的集成度、数据共享能力、约束性、交互性和错误提示等。
	界面易用性：
界面测试主要合适用户与软件之间的交互，验证用户界面中的对象是否按照预期的方式运行，并符合国家或行业标准。目前基本都有UI设计图，按照设计图的标准执行，或按照UED标准执行。
	辅助易用性：
1.	辅助系统是指帮助、向导和信息提示等辅助功能。
2.	向导测试主要关注系统的向导操作是否正确，每一步是否有说明、向导是否一致、向导是否直观。
3.	提示信息是系统用信息的形式对用户的某些操作做出的反应。
4.	用户界面测试可分为整体界面测试和界面中的元素测试：
5.	界面中整体测试是指对界面的规范性、一致性、合理性等进行测试和评估。
6.	界面中的元素测试主要包括窗口、菜单、按钮、文字等。
3.5	迁移测试用例设计
迁移测试主要是对数据迁移后的数据存储和正常使用进行的测试。迁移测试着重于老数据数据量、老数据的数据字段、老数据涉及数据表、新数据处理的正常处理和异常处理测试。
迁移用例设计原则：
1.迁移测试用例设计需要明确迁移方式和内容，以更好的覆盖到迁移数据
2.迁移测试涉及数据验证部分需要对表结构和逻辑复杂的表进行进一步分析，以覆盖到相关涉及的表内容
3.迁移测试涉及业务验证部分，需要覆盖到数据迁移以后的主要的业务场景(如时间有限可视业务的复杂度进行选择)
注意：
①迁移测试用例中需要特别用到大数据量的内容以及库表字段级的比对内容
②迁移测试用例中必须包括迁移后对新、老数据的正常业务及异常测试内容


3.6	性能测试用例设计
性能测试用例依照测试性质例分为大容量测试用例、并发测试用例、负载测试用例、压力测试用例等等
性能测试用例设计原则：
1.性能测试用例需要依照性能指标进行细化，每个性能指标都需要设计多个性能测试用例覆盖，可适用于并发用户
2.性能测试用例中需要覆盖到单业务场景和组合业务场景
3.性能测试用例中需要考虑不同软、硬件环境，因此需要特别写明性能测试用例所执行的环境要求
注意：
①性能测试用例一定要与性能测试方案、性能测试计划等对应，以更好的覆盖性能测试方案要求
②性能测试用例大多涉及到整个系统架构，因此性能测试用例复用率一般比较高，一旦系统架构发生变化，性能测试用例也需要及时进行调整。
3.7	安全测试用例设计
安全性测试是指相关考证应用程序的安全等级和辨别潜伏安全性缺点的过程。应用程序级安全测试的主要目的是查找软件自己程序设计中存在的安全隐患，并检查应用程序对非法侵入的防备能力，依据安全指标不一样测试策略也不一样。
 
图3.7.1 安全测试设计流程
软件安全测试方法主要包括主动模式和被动模式两种。在被动模式中，测试人员尽可能的了解应用逻辑：比如用工具分析所有的HTTP请求及响应，以便测试人员掌握应用程 序所有的接入点（包括HTTP头，参数，cookies等）；在主动模式中，测试人员试图以黑客的身份来对应用及其系统、后台等进行渗透测试，其可能造成的影响主要是数据破坏、拒绝服务等。一般测试人员需要先熟悉目标系统，即被动模式下的测试，然后再开展进一步的分析，即主动模式下的测试。主动测试会与被测目标进行直接的数据交互，而被动测试不需要。一般常用的安全测试方法有如下几种：
1.自动化扫描工具
2.服务器信息收集
3.文件、目录测试
4.认证测试
5.会话管理测试
6.权限管理测试
7.文件上传下载测试
8.信息泄露测试
9.输入数据测试
10.跨站脚本攻击测试
4	测试用例设计原则
4.1	测试用例设计核心思想
 
	有效性
测试人员应利用恰当的设计方法，保证测试用例必须是正确有效的。用例的验证能够符合需求规格说明书的需求，避免错误的用例和重复的用例。
	严谨性
用例的文字描述需清晰严谨，应遵循通用的书面描述语，对界定操作的用语需严谨，如且、或的严格使用，切忌口语化的描述
	合理性
测试数据应符合用户实际工作业务流程，兼顾各种业务变化的可能，人名、地名、电话号码等应具有模拟功能，符合一般的命名惯例
	可管理性
用例的编写应遵循一定的编写规范和模板，形成统一的标准文档，便于管理归档
	可重复性
用例中应包含明确的前置条件，足够详细、准确和清晰的操作步骤，保证不同人员在执行用例时没有理解歧义，既是测试执行的必要条件，也是确保测试结果可以复现的基础，尤其可确保用例能够重复使用
	可评估行
测试用例必须有正确的预期结果，执行结果的正确性是可判定的，是用来确定测试结果是否符合需求的依据
	可组织性
用例设计应考虑后期维护，应明确标注用例的状态，性质等，对用例的划分具有层级性，如根据系统功能形成树形结构，划分测试用例到不同层级的叶子节点。

总结测试用例设计思想：
	一个核心、一个基准、两个目的：
    以用户需求为核心，采用恰当、合理的测试方法作为设计用例的方法基准，以高覆盖、高复用为目的的进行测试用例设计
	两个建立三个注意：
建立高效的审核机制，建立测试用例版本跟踪管理机制；注意测试用例要素完整性，注意是否使用通顺清晰的文字描述，注意用例状态、性质等内容的正确性。
4.2	测试用例设计技巧

4.2.1	通用功能测试用例设计
任何系统都离不开增、删、改、查（搜）、登、销、上传、下载的功能，因此针对这种通用的功能测试用例设计要注意如下。
增加：除一般增加功能的测试用例外，特别注意已存在的重复增加、已删除的增加等情况测试用例
删除：除一般正常删除功能测试用例外，特别注意重复删除，删除取消等删除约束的异常情况用例
修改：除一般正常修改功能测试用例外，特别注意修改成其他已存在信息，修改为空等修改约束的情况用例
查询：特别注意初始化查询，空查询，精确查询，模糊查询，单一查询，组合条件查询的测试用例
登录：除需求要求的登录功能的校验外，特别注意重复登录（重复点击登录按钮），cookie保存等情况的用例覆盖
注销：特别注意销户后再登录，cookie处理等情况的用例
上传：需注意文件上传类型、文档上传路径有效性、文件大小、文件个数、重复文件（同名不同内容或不同名同内容）等情况的测试用例
下载：需注意下载文件类型转换、文档下载路径有效性、文件格式转换等情况测试用例
4.2.2	涉及数字的测试用例设计
1.涉及数字校验必须使用边界值法
2.数值校验需使用等价类划分法
3.需考虑数字输入的合法性（特殊符号）
4.需考虑数字长度校验情况
5.对有要求的数字个数需进行校验（如带有小数位数，需要考虑下搜狐点前及小数点后的位数情况）
6.需要考虑输入法的识别情况（全角、半角）
4.2.3	涉及日期的测试用例设计
1.需要考虑日期格式合法性输入（YYYYMMDD）
2.需要考虑日期输入合法性校验（88888888）
3.日期测试用例需考虑特殊日期的处理（2.29）
注：目前日期基本都用使用日期控件，日期的选择需根据需求，如需求约束今天以前不允许选择，如时间段的设定截止日期必须大于开始日期等
4.2.4	涉及输入框的测试用例设计
1.输入框需考虑字段长度校验
2.需考虑字段类型校验
3.需考虑对不同语言文字的处理情况
4.需考虑对乱码的处理情况
5.需考虑输入法（全角、半角）的情况
6.需考虑常用快捷操作是否实现（如Ctrl+V的情况）
7.B/S结构需考虑文字编码情况
8.必填项校验
4.2.5	涉及按钮的测试用例设计
1.输入重复点击情况
2.需考虑Enter快捷键的情况
3.reset按钮清空情况
4.2.6	涉及下拉、单选、复选框的测试用例设计
1.下拉框：选择数据后是否有联动效果、点击后下拉显示数据内容、点击空白后下拉框收缩
2.单选框：选中、更换
3.复选框：选中、取消
4.2.7	涉及分页的测试用例设计
1.下拉框条数选择
2.首页、上一页、下一页、尾页
3.GO、输入框页数
4.2.8	涉及弹窗的测试用例设计
1.注意弹窗的确认或取消
2.注意弹窗右上角的关闭
3.注意点击弹窗外其他区域页面的响应
4.2.9	测试用例设计的共性
1.测试用例文档要素基本相同。包括测试用例编号、测试用例目的、测试用例前置条件、操作步骤、预期结果等内容
2.测试用例设计方法一致。大多数白盒测试用例设计均包含了路径覆盖或是最基本的语句覆盖法，而大多数黑盒测试用例设计都会用到边界值法、等价类、场景法的相关内容
3.测试用例设计目的一致。均是为了保证测试对象功能实现正确性

Web端页面功能用例设计测试点：
1.	页面元素检查：
	页面标题；
	页面所有控件及对应的字段名称（按钮、文本框、下拉框、单选框、复选框、日期控件）；
	控件是否有默认值显示以及对应的数据来源；
	控件是否可编辑；
	必填项校验（必填项的显示效果检查）；
	校验控件的格式、长度（有则需描述，无则略过）；
	页面包含的列表字段名称（有则需描述，无则略过该条件）；
【注】页面检查在查询、新增、编辑、审批页面需要添加描述
2.	查询：
	列表默认数据（如果无数据显示是否有提示信息）；
	列表默认排序；
	哪些字段支持排序功能；
	单条件查询（每个查询条件均需编写用例，需描述是否支持模糊查询）；
	全条件查询；
3.	新增：
	必填项效果检查（未填写保存后的提示效果，如：弹出必填提示信息，点击后光标定位到必填项文本框等）；
	保存功能（必填项未填写，保存弹出提示）；
1)	全部字段信息填写；
2)	只填写必填项；
	保存成功提示语；
	保存成功后停留在那个页面（新增页面、列表页面）；
	新增成功后需检查信息被添加至列表页面；
	列表页面显示的字段信息为新增时填写的信息；
4.	编辑：
	字段需显示之前填写的信息；
	必填项效果检查（未填写保存后的提示效果，如：弹出必填提示信息，点击后定位到必填项文本框等）；
	字段是否可编辑；
	单字段修改；
	全部字段修改；
	保存功能（必填项未填写保存弹出提示；单字段修改保存成功后编辑页面/列表页面只是单个字段的信息被修改）；
	保存成功提示；
	保存成功后停留在那个页面（新增页面、列表页面）；
	修改成功后需检查信息被添加至列表页面；
	列表页面显示的字段信息为修改时填写的信息；
5.	删除：
	信息是否被引用；
	单个删除；
	批量删除；
	复选框的选中/取消；
	删除弹出的提示；
	删除成功的提示；
6.	呈递：
	呈递后的审批人；
	呈递后添加一条信息至列表页面；
	呈递审批列表页面查看下一节点的接收人；
	呈递审批列表显示目前流程的进度；
	呈递审批列表显示审批单的状态；
	发送任务给审批人；
7.	审批：（分审批通过、审批拒绝2种结果书写）
	页面需显示呈递的信息；
	单个审批；
	批量审批；
	必填项效果检查（如：审批拒绝，须填写拒绝原因）；
	审批后添加一条信息至呈递审批列表页面；
	呈递审批列表页面可查看下一节点的接收人；
	呈递审批列表显示目前流程的进度；
	呈递审批列表显示审批单的状态；
	发送任务给审批人；（每个节点审批均需要检查）
	终节点的审批人，审批通过需发送一条通知给申请人
	每个节点的审批人，审批拒绝需发送一条通知给申请人（每个节点审批均需要检查）
8.	上传附件：
	页面特殊的附件需描述；
	链接跳转至那个页面需描述；
	附件个数；
	新附件是否覆盖之前的旧附件；
	附件格式筛选；
	附件提示；
	附件上传成功在列表页面显示信息；
	附件的操作；
    
9.	返回：
	返回至XX页面；
	链接跳转是否正确；

要求：
1)	按照特有的条件（如：不同类型的餐厅、不同角色）分开书写测试用例步骤
2)	按照“查看页面、操作页面、保存页面、辅助功能的操作”的顺序书写测试用例
4.3	测试用例设计步骤
通常情况下用例设计的完整流程，基本遵循以下步骤：
1.	测试需求分析：
从项目需求分析文档/概要设计/详细设计/原型图中，了解出项目的需求。通过测试人员自己的分析、 理解，整理成为测试需求，使测试人员能清楚被测项目包含的功能点。
2.	业务流程分析：
分析了解被测试项目所属的行业及其业务知识。对被测项目的业务流程要全部梳理出来（可画出项目的流程图，也可用头脑风暴）。
项目的流程：主线流程、分支流程、数据流转，流转过程中关键点的判断条件以及完成操作的一些非必要条件。
3.	测试用例设计：
主要包括功能测试、界面测试、兼容性测试、易用性测试、异常测试、性能测试、压力测试等，在设计用例时要尽量考虑录入正常、边界、异常值等系统的处理情况   
4.	测试用例评审：
由测试用例设计者发起，参加的人员需包括测试负责人、项目经理、 开发人员及其他相关的测试人员。
5.	测试用例完善：
测试用例编写完成之后需不断完善，软件产品新增功能或更新需求后， 测试用例必须配套修改更新；在测试过程中发现设计测试用例时考虑不周，需要对测试用例进行修改完善；在软件交付使用后客户反馈的软件缺陷，而缺陷又是因测试用例存在漏洞造成，也需要对测试用例进行完善。














5	测试用例编写及管理
5.1	测试用例编写规范
测试用例编写一般都会提供固定的模板，这些模板中包含一些必要的用例元素，通常情况下个用例要包括需要测试的功能、应输入的数据和预期的输出结果。测试数据应该选用少量、高效的测试数据进行尽可能完备的测试；基本目标是：设计一组发现某个错误或某类错误的测试数据。

5.1.1	测试用例命名规则
以功能模块和业务流程进行命名，一级目录使用个项目的顶级菜单名称来命名，二级目录使用顶级菜单下的二级菜单名称类命名，用具可根据名字判别该用例是测试那个模块的，各用例根据各用例的功能来命名，经理简介明了，同一目录下的用例名字字数最好相同
5.1.2	测试用例编号规则
用例编号规则：以测试模块名称的第一个字母进行命名（大写），若测试模块名称比较长时，可进行简写。一般简拼不超过5个字母：如：
	测试模块为“用户管理”，功能编号为“YHGL”；
	测试模块为“行政单位管理”，功能编号为“DWGL”
	功能编号规则直接以001、002、003…..
5.1.3	测试用例文档书写内容
1、被测试对象的介绍
2、测试范围与目的
3、测试环境与测试辅助工具的描述
4、功能测试用例主要元素
	前置/操作描述：
1、前置条件（可选）：系统权限配置或前、后台配置描述（所有进行操作的前提条件）。                                
2、操作：测试的操作步骤描述。     
	功能点： 功能点描述。
	输入数据：前期数据准备。可揉和在操作步骤中。
	预期结果：描述输入数据后程序应该输出的结果。
	测试结果：描述本条用例的实际测试情况，并判断实际测试结果与预期结果的差别。
	Bug编号/Bug简要描述:需要进流程的对应事物流程的编号，及简要说明。
	优先级：用例执行优先级顺序
	创建者：用例设计编写者
	备注：测试过程中遇到的问题等情况说明。
5.1.4	测试用例编写注意事项
	测试目的明确：一定要写明测试目的是什么，而不是的描述为对业务合法性校验。
	测试场景覆盖：一定要在用例中充分考虑不同的业务场景。例如总行对分行的操作，同一清算中心的支行间是否可以进行相关操作等。
	前后关联业务、关联场景的覆盖全面：如一定要考虑到前置交易是什么，后续的交易是什么，将整个业务流程串联起来。
	预期结果一定描述准确，例如报错信息一定要写明系统具体报错内容，而非简单的说明系统报错。
	测试用例中一定特别说明测试范围切记注意不要将一个测试点当为一个测试用例。
	测试用例的要素一定要完整
	用例的文字描述清晰易懂
5.2	测试用例管理
5.2.1	目录
模块功能的测试用例在编写中采用树形目录来划分，树形目录按照模块功能来划分，第一级为系统名称，第二级为子系统名称，第三级为模块名称。当模块中有多个TAB页时，可列在第四级，目录最深为四级，若有更深层次的页面可提升到第四级中。
5.2.2	优先级
如何有效的维护和优化用例，就是需要前期明确的分类规划，根据分类的优先级一步一步地来完成就可以了，这样，我们也可以有效把控的测试覆盖度。根据二八原则或者称数据统计，前20%的用例可以发现80%的重要BUG。当设计测试用例时，分配优先级非常不容易，且这个优先级也不是固定不变的，常见用例优先级划分如下：
最高：
BVTs（Build Verification tests）也叫冒烟测试用例，一组你运行以确定这个build版本是否可测的测试用例。
高：
这种用例运行，能发现重要的错误，或者它能够保证软件的功能是稳定的。俗称大的基本功能的测试用例。
中：
检查功能的一些细节，包括边界，配置测试。
低：
较少执行的测试用例，并不代表它不重要，而是说不是经常被运行。例如压力测试错误信息等。
用例级别设置：如果没有很多的时间来确定优先级，那么可以先大致的进行划分：把所有功能性验证的用例标注为高；把边界值或错误能力的用例标注为中；把非功能性和易用性的标注为低。
提升和降级：针对1描述的所有高级别的功能性用例划分为重要和不十分重要两种，然后重要的保持高，不十分重要的降级为中。同理，对应中级别的用例，重要的进行升级，不十分重要的保持中。对应低级别的，重要的升级，不十分重要的保持。
确定BVTs：将高优先级的用例划分为严重和重要， 严重的将升级为bvts，经过这个流程后，大致会控制bvt10%、高为25%、中55%、低10%，但具体还要结合具体的项目和质量目标确定。
一般，划分测试用例级别是我们会假设发现bug的严重程度和bug对应的测试用例的优先级是平行的，这样可以根据发现bug的程度来划分对应测试用例的级别。

5.2.3	用例评审
测试用例评审流程规范主要为开展测试用例评审工作提供指引，规范测试用例评审管理工作。
 
图5.2.1测试用例评审流程
测试用例评审流程内容：
1、前提
通常情况下测试用例提出评审需测试人员编写完一个完整的功能模块的测试用例或已完成所有测试用例的编写。也可根据实际情况对梳理的测试点进行线下会议评审，根据会议评审结果完善测试点后输出完整用例文档，进行线上会签评审。
2、流程输入
	测试用例
	需求规格说明
3、流程输出
	问题记录清单
	测试用例评审报告
4、参与评审人员
项目经理、测试负责人、测试人员、需求分析人员、架构设计人员、开发人员
5、评审方式
召开评审会议。与会者在测试用例编写人员讲解之后给出意见或建议，同时记录下评审会议记录；
通过邮件、及时通讯工具与相关人员沟通。
　　无论采用哪种方式，都应该在评审之前事先把需要评审的测试用例相关文档以邮件的形式发给参与评审的相关人员，同时在邮件中提醒参与评审的相关人员在评审前查阅一遍评审内容，并记录相关问题，以便在评审会议上提出，以节省沟通成本。
6、评审用例检查清单
	测试用例是否按照公司定义的模板进行编写的
	测试用例的本身的描述是否清晰，是否存在二义性
	测试用例内容是否正确，是否与需求目标相一致
	测试用例的期望结果是否确定、唯一的
	操作步骤应与描述是否相一致
	测试用例是否覆盖了所有的需求
	测试设计是否存在冗余性
	测试用例是否具有可执行性
	是否从用户层面来设计用户使用场景和业务流程的测试用例
	场景测试用例是否覆盖最复杂的业务流程
	用例设计是否包含了正面、反面的用例
	对于由系统自动生成的输出项是否注明了生成规则
	测试用例应包含对中间和后台数据的检查
	测试用例应有正确的名称和编号
	测试用例应标注有执行的优先级
	测试用例包含相关的配置信息：测试环境、数据、前置测试用例、用户授权等
	每个测试用例步骤应<=15 Step
	自动化测试脚本必须带有注释（注释应包括：目的、输入、期望结果等）
	非功能测试需求或不可测试需求是否在用例中列出并说明
7、退出标准
	评审过程中收集相关人员的反馈信息（即问题记录清单），并在此基础上进行测试用例更新，直到评审通过
	评审结束后，测试负责人出测试用例评审报告给到相关人员
	评审结果经项目经理同意确认
8、控制机制
采用会议评审时，主持人应把握会议进度，尽量按时有效的完成评审工作
9、输出清单
	问题记录清单
	测试用例评审报告

5.2.4	用例维护
软件产品的版本是随着软件的升级而不断变化的，而每一次版本的编号都会对测试用例产生影响，所以测试用例集也需要不断地变更和维护，使之与产品的编号报错一致。
以下原因可能导致测试用例变更：
	软件需求变更，软件需求变更可能导致软件功能的增加、删除、修改等变化，应遵循需求变更控制管理方法，同样变更的测试用例也需要执行变更管理流程。
	测试需求的遗漏和误解，由于测试需求分析不到位，可能导致测试需求遗漏或者误解，相应的测试用例也要进行变更。
	软件自身的新增功能以及软件版本的更新，测试用例也必须配套修改更新。
一般小的修改完善可在原测试用例文档上修改，但文档要有更改记录。软件的版本升级更新，测试用例一般也应随之编制升级更新版本。
6	测试用例执行
6.1	测试用例执行结果
测试员执行测试用例后需要对执行的用例进行分类统计，一遍进行相关数据度量，这就需要一个分类标志，一般都是以执行结果来分：
	通过（Pass）
执行测试用例，实际结果与预期结果一致。
	不通过（Failed）
用户执行用例时，实际结果与预期结果不相符。在记录执行结果不通过时应注明原因。
	未执行（unexecuted）
一些外界原因导致用例不能正常进行，导致此状态原因有时间不足，推迟缺陷，安装问题，超出范围，或由于其他缺陷导致不能执行用例等。
6.2	相关度量
测试用例执行结果可以从覆盖率、执行率、通过率等几个方面进行分析和考察。测试用例覆盖率是只测试用例覆盖的功能与测试需求功能的比值；测试用例执行率是指已执行的测试用例数与测试用例总数的比值；测试用例通过率是指成功执行的测试用例数与测试用例总数的比值。
测试用例相关度量：
	平均产出用例数
日平均产出用例数是测试员平均每天能编写的用例数，用来衡量测试员的编写用例能力，测试负责人可以依据此来安排工作时间和分配工作任务，具体算法如下：
日平均产出用例数 = 用例总数/编写天数
	日平均执行用例数
日平均执行用例数是测试员每天平均能执行的用例个数，用来衡量测试员的执行用例能力，测试负责人可以依据此来安排工作时间和分配工作任务，具体算法如下：
日平均执行用例数 = 用例总数/执行用例天数
	用例覆盖率
用例覆盖率是用来度量目前已编写用例的需求占总需求的百分比，即测试用例编写完成的百分比，项目经理和测试负责人可以通过这个数据清楚的知道测试用例编写完成的工作量及剩余工作量，通过完成工作量花费时间估算出剩余工作需要的工作时间，具体算法如下：
用例覆盖率 = 用例总数/需求总数*100%
测试用例的覆盖率需要达到100%，也就是说测试用例必须覆盖全部的测试需求，否则测试用例的设计则是不全面的，无法保证测试质量，需要补充或者重新设计相应测试用例。
	用例执行率
用例执行率用于度量目前已执行用例数的百分比，即执行测试用例的工作中完成了多少的工作量，项目经理和测试负责人可以通过这个数据清楚的知道测试执行工作完成的工作量及剩余工作量，具体算法如下：
用例执行率 = 已执行的用例数/测试用例总数*100%
测试用例执行率是衡量测试效率的因素，一般说来，在测试完成时测试用例的执行率也需要达到100%，也可能因为某些特殊原因导致测试中断而没有全部执行测试用例，可针对具体的情况进行分析。
	用例通过率
用例通过率是测试员执行完所有用例后，执行通过的用例数与执行用例总数的百分比，项目经理和测试负责人可以通过此数据评估项目当前版本的质量，对后面工作计划有针对性的做出改进。 
用例通过率 = 执行通过用例数/执行用例总数*100%
测试用例通过率是衡量用例本身设计质量和被测软件质量的因素，对于未能成功执行的测试用例，要分析是用例设计错误还是被测软件错误，导致用例无法顺利执行。
	用例有效率
用例有效率是用来衡量测试用例的设计则是否全面的重要依据，若值=1，说明用例设计合理、全面，无遗漏；值大于1时，说明测试用例设计不全面，值越大说明测试用例设计中遗漏需求越多。
用例有效率 = 总缺陷数/（执行用例总数-执行通过用例数）






7	相关模板
1.测试用例模板
 
 
2.用例版本维护模板
 
3. 执行版本
A.	单元测试（此处单元测试指本系统中单模块测试）：
版本号	版本说明
V0.1	对所有主要功能进行测试
V0.2	
V0.3	
V0.4	
V0.5	
V0.6	执行所有功能、UI、控件测试用例
V0.7	
V0.8	
V0.9	BUG回测
V1.0	
说明：第一轮测试5个版本，第二轮测试3个版本，第三轮2个版本，共计10个版本

B.	集成测试：
版本号	版本说明
V0.1	执行所有的集成测试用例
V0.2	
V0.3	
V0.4	
V0.5	
V0.6	回测BUG以及执行页面UI以及页面控件测试用例
V0.7	
V0.8	
V0.9	BUG回测
V1.0	
说明：第一轮测试5个版本，第二轮测试3个版本，第三轮2个版本，共计10个版本

C.	系统测试：
版本号	版本说明
V0.1	在不同客户端环境下进行全面测试
V0.2	
V0.3	
V0.4	
V0.5	
V0.6	BUG回测
V0.7	
V0.8	
V0.9	进行上线前的全面测试
V1.0	
说明：第一轮测试5个版本，第二轮测试3个版本，第三轮2个版本，共计10个版本

